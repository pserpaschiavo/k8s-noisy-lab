[2025-05-11 15:32:29] Handlers de sinal configurados. Use CTRL+C para interromper o experimento com limpeza segura.
[2025-05-11 15:32:29] Iniciando experimento: firsts-analisys-3
[2025-05-11 15:32:29] Log sendo salvo em: /home/phil/Projects/k8s-noisy-lab/results/2025-05-11/15-32-29/firsts-analisys-3/experiment.log
[2025-05-11 15:32:29] Verificando pr√©-requisitos...
[2025-05-11 15:32:29] M√©tricas ser√£o salvas em: /home/phil/Projects/k8s-noisy-lab/results/2025-05-11/15-32-29/firsts-analisys-3
[2025-05-11 15:32:29] Intervalo de coleta: 5 segundos
[2025-05-11 15:32:29] Validando recursos do cluster...
[0;35m==========================================[0m
[0;35m     VERIFICA√á√ÉO PR√â-EXPERIMENTO         [0m
[0;35m==========================================[0m
[0;35mVerificando conectividade com o cluster...[0m
[0;32m‚úì Conex√£o com o cluster estabelecida com sucesso[0m
[0;35mVerificando estado dos n√≥s do cluster...[0m
[0;32m‚úì O cluster possui 1 n√≥s dispon√≠veis[0m
[0;35mVerificando recursos dispon√≠veis no cluster...[0m
CPU: [0;35m11[0m cores
Mem√≥ria: [0;35m28.73[0m GB
[0;32m‚úì Recursos do cluster s√£o suficientes para o experimento[0m
[0;35mVerificando namespaces necess√°rias...[0m
[0;32m‚úì Namespace 'tenant-a' encontrada[0m
[0;32m‚úì Namespace 'tenant-b' encontrada[0m
[0;32m‚úì Namespace 'tenant-c' encontrada[0m
[0;32m‚úì Namespace 'monitoring' encontrada[0m
[0;35mVerificando disponibilidade do Prometheus...[0m
[0;32m‚úì Prometheus est√° rodando e pronto[0m
[0;35mVerificando disponibilidade das m√©tricas essenciais...[0m
[0;32m‚úì M√©trica 'container_cpu_usage_seconds_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_memory_working_set_bytes' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_network_receive_bytes_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_network_transmit_bytes_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_cpu_cfs_throttled_periods_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_cpu_cfs_periods_total' dispon√≠vel[0m
[0;35mVerificando permiss√µes necess√°rias...[0m
[0;35mVerificando CRDs do Prometheus Operator...[0m
[0;32m‚úì CRD 'servicemonitors.monitoring.coreos.com' encontrada[0m
[0;32m‚úì CRD 'prometheusrules.monitoring.coreos.com' encontrada[0m
[0;35m==========================================[0m
[0;32m‚úì Cluster validado com sucesso para o experimento[0m
[0;35m==========================================[0m

Informa√ß√µes adicionais:
- O experimento utiliza m√©tricas da cAdvisor integradas ao kubelet
- As queries do Prometheus usam principalmente m√©tricas rate() com 1m de janela
- Os workloads s√£o distribu√≠dos em 3 tenants para simular o cen√°rio de noisy neighbour

Recomenda√ß√µes finais:
- Certifique-se de ter pelo menos 15-20% de recursos livres al√©m dos solicitados
- Se estiver usando Minikube, use a op√ß√£o '--driver=docker' para melhor desempenho
- Verifique se n√£o h√° outros processos consumindo recursos significativos nos n√≥s
[2025-05-11 15:32:33] Criando namespaces...
[2025-05-11 15:32:33] Namespace 'tenant-a' j√° existe.
[2025-05-11 15:32:33] Namespace 'tenant-b' j√° existe.
[2025-05-11 15:32:33] Namespace 'tenant-c' j√° existe.
[2025-05-11 15:32:33] Namespace 'tenant-d' j√° existe.
[2025-05-11 15:32:33] Namespace 'monitoring' j√° existe.
[2025-05-11 15:32:33] Namespace 'ingress-nginx' j√° existe.
NAME              STATUS   AGE
default           Active   70m
ingress-nginx     Active   70m
kube-node-lease   Active   70m
kube-public       Active   70m
kube-system       Active   70m
metallb-system    Active   65m
monitoring        Active   70m
tenant-a          Active   70m
tenant-b          Active   70m
tenant-c          Active   70m
tenant-d          Active   70m
[2025-05-11 15:32:38] Aplicando resource quotas...
resourcequota/tenant-a-quota configured
resourcequota/tenant-b-quota unchanged
resourcequota/tenant-c-quota configured
resourcequota/tenant-d-quota unchanged
[2025-05-11 15:32:44] Verificando quotas de recursos...
NAMESPACE   NAME             AGE   REQUEST                                                 LIMIT
tenant-a    tenant-a-quota   63m   requests.cpu: 1/1500m, requests.memory: 1280Mi/2Gi      limits.cpu: 2/3, limits.memory: 2560Mi/4Gi
tenant-b    tenant-b-quota   63m   requests.cpu: 2500m/3, requests.memory: 2816Mi/4Gi      limits.cpu: 5800m/6, limits.memory: 7680Mi/8Gi
tenant-c    tenant-c-quota   63m   requests.cpu: 550m/1500m, requests.memory: 1344Mi/3Gi   limits.cpu: 1/3, limits.memory: 2176Mi/6Gi
tenant-d    tenant-d-quota   63m   requests.cpu: 600m/2, requests.memory: 1152Mi/2Gi       limits.cpu: 1200m/4, limits.memory: 1792Mi/4Gi
[2025-05-11 15:32:44] Namespace 'monitoring' j√° existe.
[2025-05-11 15:32:44] Verificando o estado do Prometheus...
[2025-05-11 15:32:44] Verificando pods do Prometheus...
[2025-05-11 15:32:44] Verificando servi√ßos do Prometheus...
[2025-05-11 15:32:45] Encontrado servi√ßo do Prometheus: prometheus-operated
[2025-05-11 15:32:47] Configurando port-forward para o Prometheus...
Unable to listen on port 9090: Listeners failed to create with the following errors: [unable to create listener: Error listen tcp4 127.0.0.1:9090: bind: address already in use unable to create listener: Error listen tcp6 [::1]:9090: bind: address already in use]
error: unable to listen on any of the requested ports: [{9090 9090}]
[2025-05-11 15:32:52] Prometheus est√° acess√≠vel via localhost:9090
[2025-05-11 15:32:52] Prometheus tem 73 targets ativos
[2025-05-11 15:32:52] Verifica√ß√£o do Prometheus conclu√≠da
[2025-05-11 15:32:52] Ajustando dura√ß√µes nos manifestos de acordo com as dura√ß√µes das fases...
[2025-05-11 15:32:52] Dura√ß√£o total do experimento (estimada): 300s para 1 rounds
[2025-05-11 15:32:52] Dura√ß√£o m√≠nima dos workloads: 390s (inclui margem de seguran√ßa de 30%)
[2025-05-11 15:32:52]   - Ajustada dura√ß√£o do nginx-benchmark para 390s
[2025-05-11 15:32:52]   - Ajustada dura√ß√£o do continuous-memory-stress para 390s
[2025-05-11 15:32:52]   - Ajustada dura√ß√£o dos workloads cont√≠nuos do tenant-d para 390s
[2025-05-11 15:32:52]   - Ajustado timeout do stress-ng para 160s
[2025-05-11 15:32:52] Manifestos ajustados com sucesso!
[2025-05-11 15:32:52]   - Verificadas configura√ß√µes adicionais de dura√ß√£o no tenant-a
[2025-05-11 15:32:52] ======= IN√çCIO DO EXPERIMENTO: firsts-analisys-3 =======
[2025-05-11 15:32:52] Data: 2025/05/11, Hora: 15:32:29
[2025-05-11 15:32:52] N√∫mero de rounds: 1
[2025-05-11 15:32:52] Dura√ß√£o das fases: Baseline=100s, Ataque=100s, Recupera√ß√£o=100s
[2025-05-11 15:32:52] Intervalo de coleta de m√©tricas: 5s
[2025-05-11 15:32:52] ===== ROUND 1/1 =====
[2025-05-11 15:32:52] Limpando workloads para come√ßar o round 1 com um ambiente limpo...
deployment.apps "nginx-deployment" deleted
configmap "nginx-config" deleted
service "nginx" deleted
job.batch "nginx-benchmark" deleted
deployment.apps "iperf-server" deleted
service "iperf-server" deleted
deployment.apps "stress-ng" deleted
deployment.apps "traffic-generator" deleted
deployment.apps "traffic-server" deleted
configmap "nginx-traffic-server-config" deleted
service "traffic-server" deleted
service "redis" deleted
deployment.apps "redis-deployment" deleted
job.batch "continuous-memory-stress" deleted
deployment.apps "memory-monitor" deleted
persistentvolumeclaim "postgres-data" deleted
configmap "postgres-config" deleted
service "postgres" deleted
deployment.apps "postgres" deleted
job.batch "pgbench-init" deleted
job.batch "pgbench-continuous-workload" deleted
job.batch "cpu-intensive-continuous" deleted
job.batch "disk-intensive-continuous" deleted
error: error parsing /home/phil/Projects/k8s-noisy-lab/manifests/tenant-d/cpu-disk-workload.yaml: error converting YAML to JSON: yaml: line 94: could not find expected ':'
[2025-05-11 15:32:54] Aguardando finaliza√ß√£o completa dos recursos anteriores...
pod/iperf-server-d79fbdf6c-fct9p condition met
pod/nginx-benchmark-5nsvs condition met
pod/nginx-deployment-56fc57d4-sl9hw condition met
pod/continuous-memory-stress-jbd2q condition met
pod/memory-monitor-cfd7584c6-6gfvj condition met
[2025-05-11 15:33:25] === Fase 1 - Baseline ===
[2025-05-11 15:33:25] Coletando m√©tricas a cada 5 segundos...
[2025-05-11 15:33:25] Coleta de m√©tricas iniciada com PID: 529980 (log: /home/phil/Projects/k8s-noisy-lab/results/2025-05-11/15-32-29/firsts-analisys-3/round-1/1 - Baseline/logs/metrics_collection.log)
[2025-05-11 15:33:25] Iniciando fase: 1 - Baseline com dura√ß√£o m√°xima de 100s
[2025-05-11 15:33:25] Implantando tenant-a (sens√≠vel √† rede)...
[2025-05-11 15:33:25] Prometheus j√° est√° acess√≠vel via localhost:9090
deployment.apps/nginx-deployment created
configmap/nginx-config created
service/nginx created
job.batch/nginx-benchmark created
deployment.apps/iperf-server created
service/iperf-server created
[2025-05-11 15:33:25] Aguardando inicializa√ß√£o dos servi√ßos do tenant-a...
deployment.apps/nginx-deployment condition met
[2025-05-11 15:33:27] Implantando tenant-c (v√≠tima)...
service/redis created
deployment.apps/redis-deployment created
job.batch/continuous-memory-stress created
deployment.apps/memory-monitor created
[2025-05-11 15:33:27] Implantando tenant-d (CPU e Disco)...
persistentvolumeclaim/postgres-data created
configmap/postgres-config created
service/postgres created
deployment.apps/postgres created
job.batch/pgbench-init created
job.batch/pgbench-continuous-workload created
job.batch/cpu-intensive-continuous created
job.batch/disk-intensive-continuous created
error: error parsing /home/phil/Projects/k8s-noisy-lab/manifests/tenant-d/cpu-disk-workload.yaml: error converting YAML to JSON: yaml: line 94: could not find expected ':'
[2025-05-11 15:35:05] Fase 1 - Baseline conclu√≠da
[2025-05-11 15:35:05] Interrompendo coleta de m√©tricas (PID: 529980)...
[2025-05-11 15:35:05] Coleta de m√©tricas finalizada.
[2025-05-11 15:35:05] Fase '1 - Baseline' conclu√≠da.
[2025-05-11 15:35:05] Modo n√£o interativo: continuando automaticamente para a pr√≥xima fase...
[2025-05-11 15:35:05] === Fase 2 - Attack ===
[2025-05-11 15:35:05] Coletando m√©tricas a cada 5 segundos...
[2025-05-11 15:35:05] Coleta de m√©tricas iniciada com PID: 552654 (log: /home/phil/Projects/k8s-noisy-lab/results/2025-05-11/15-32-29/firsts-analisys-3/round-1/2 - Attack/logs/metrics_collection.log)
[2025-05-11 15:35:05] Iniciando fase: 2 - Attack com dura√ß√£o m√°xima de 100s
[2025-05-11 15:35:05] Implantando tenant-b (atacante noisy neighbor)...
deployment.apps/stress-ng created
deployment.apps/traffic-generator created
deployment.apps/traffic-server created
configmap/nginx-traffic-server-config created
[2025-05-11 15:35:05] Prometheus j√° est√° acess√≠vel via localhost:9090
service/traffic-server created
[2025-05-11 15:35:05] Aguardando inicializa√ß√£o dos servi√ßos do tenant-b...
deployment.apps/traffic-generator condition met
[2025-05-11 15:36:45] Timeout de fase 2 - Attack atingido. Matando processo 552660
[2025-05-11 15:36:45] Fase 2 - Attack conclu√≠da
[2025-05-11 15:36:45] Interrompendo coleta de m√©tricas (PID: 552654)...
[2025-05-11 15:36:45] Coleta de m√©tricas finalizada.
[2025-05-11 15:36:45] Fase '2 - Attack' conclu√≠da.
[2025-05-11 15:36:45] Modo n√£o interativo: continuando automaticamente para a pr√≥xima fase...
[2025-05-11 15:36:45] === Fase 3 - Recovery ===
[2025-05-11 15:36:45] Coleta de m√©tricas iniciada com PID: 574479 (log: /home/phil/Projects/k8s-noisy-lab/results/2025-05-11/15-32-29/firsts-analisys-3/round-1/3 - Recovery/logs/metrics_collection.log)
[2025-05-11 15:36:45] Iniciando fase: 3 - Recovery com dura√ß√£o m√°xima de 100s
[2025-05-11 15:36:45] Coletando m√©tricas a cada 5 segundos...
[2025-05-11 15:36:45] Removendo tenant-b (atacante)...
[2025-05-11 15:36:45] Prometheus j√° est√° acess√≠vel via localhost:9090
deployment.apps "stress-ng" deleted
deployment.apps "traffic-generator" deleted
deployment.apps "traffic-server" deleted
configmap "nginx-traffic-server-config" deleted
service "traffic-server" deleted
[2025-05-11 15:36:46] Verificando recupera√ß√£o do tenant-a, tenant-c e tenant-d...
[2025-05-11 15:36:46] Verificando se todos os tenants relevantes para a fase 'recovery' est√£o prontos...
[2025-05-11 15:36:46] Aguardando pods no namespace tenant-a ficarem prontos (timeout: 120s)...
[2025-05-11 15:36:46] Status dos pods em tenant-a:
[2025-05-11 15:36:46] Detalhes dos pods com problemas:
[2025-05-11 15:36:52] Aguardando pods no namespace tenant-a... (5/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:36:57] Aguardando pods no namespace tenant-a... (10/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:37:03] Status dos pods em tenant-a:
[2025-05-11 15:37:03] Detalhes dos pods com problemas:
[2025-05-11 15:37:08] Aguardando pods no namespace tenant-a... (20/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:37:13] Aguardando pods no namespace tenant-a... (25/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
error: timed out waiting for the condition on deployments/traffic-server
[2025-05-11 15:37:19] Status dos pods em tenant-a:
[2025-05-11 15:37:19] Detalhes dos pods com problemas:
[2025-05-11 15:37:24] Aguardando pods no namespace tenant-a... (35/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:37:29] Aguardando pods no namespace tenant-a... (40/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:37:34] Status dos pods em tenant-a:
[2025-05-11 15:37:34] Detalhes dos pods com problemas:
[2025-05-11 15:37:40] Aguardando pods no namespace tenant-a... (50/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:37:45] Aguardando pods no namespace tenant-a... (55/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:37:50] Status dos pods em tenant-a:
[2025-05-11 15:37:50] Detalhes dos pods com problemas:
[2025-05-11 15:37:55] Aguardando pods no namespace tenant-a... (65/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:38:00] Aguardando pods no namespace tenant-a... (70/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:38:06] Status dos pods em tenant-a:
[2025-05-11 15:38:06] Detalhes dos pods com problemas:
[2025-05-11 15:38:11] Aguardando pods no namespace tenant-a... (80/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:38:16] Aguardando pods no namespace tenant-a... (85/120s) - 1 pods ainda n√£o prontos, 0 n√£o em execu√ß√£o
[2025-05-11 15:38:21] Status dos pods em tenant-a:
[2025-05-11 15:38:21] Detalhes dos pods com problemas:
[2025-05-11 15:38:25] Timeout de fase 3 - Recovery atingido. Matando processo 574483
[2025-05-11 15:38:25] Fase 3 - Recovery conclu√≠da
[2025-05-11 15:38:25] Interrompendo coleta de m√©tricas (PID: 574479)...
[2025-05-11 15:38:25] Coleta de m√©tricas finalizada.
[2025-05-11 15:38:25] Round 1/1 conclu√≠do com sucesso!
[2025-05-11 15:38:25] Modo n√£o interativo: limpando automaticamente os recursos dos tenants...
[2025-05-11 15:38:25] Limpando todos os tenants ap√≥s o experimento...
namespace "tenant-a" deleted
namespace "tenant-b" deleted
namespace "tenant-c" deleted
namespace "tenant-d" deleted
[2025-05-11 15:39:03] Tenants removidos com sucesso.
[2025-05-11 15:39:03] Recursos dos tenants removidos.
[2025-05-11 15:39:03] ======= EXPERIMENTO CONCLU√çDO =======
[2025-05-11 15:39:03] Data/hora de in√≠cio: 2025/05/11 15:32:29
[2025-05-11 15:39:03] Data/hora de t√©rmino: 2025/05/11 15:39:03
[2025-05-11 15:39:03] Dura√ß√£o total: 333 segundos (5 minutos)
[2025-05-11 15:39:03] M√©tricas e logs salvos em: /home/phil/Projects/k8s-noisy-lab/results/2025-05-11/15-32-29/firsts-analisys-3
[2025-05-11 15:39:03] Para visualizar os resultados no Grafana:
[2025-05-11 15:39:03] kubectl -n monitoring port-forward svc/prometheus-grafana 3000:80
[2025-05-11 15:39:03] Abra seu navegador em http://localhost:3000 (usu√°rio: admin, senha: admin)
[2025-05-11 15:39:03] ===== INTERRUP√á√ÉO DETECTADA =====
[2025-05-11 15:39:03] Experimento terminado com erro (c√≥digo: 0)
[2025-05-11 15:39:03] Realizando limpeza de recursos...
[2025-05-11 15:39:03] Interrompendo port-forwards em execu√ß√£o...
[2025-05-11 15:39:03] Removendo recursos do tenant-b (atacante)...
[2025-05-11 15:39:03] Modo n√£o interativo: limpando automaticamente todos os recursos dos tenants...
[2025-05-11 15:39:03] Limpando todos os tenants ap√≥s o experimento...
[2025-05-11 15:39:03] Tenants removidos com sucesso.
[2025-05-11 15:39:03] Recursos dos tenants removidos.
[2025-05-11 15:39:03] Limpeza de emerg√™ncia conclu√≠da.
[2025-05-11 15:39:03] M√©tricas e logs parciais salvos em: /home/phil/Projects/k8s-noisy-lab/results/2025-05-11/15-32-29/firsts-analisys-3
[2025-05-11 15:39:03] ===== FIM DO EXPERIMENTO (INTERROMPIDO) =====
