[2025-05-09 03:37:26] Iniciando experimento: cpu-noisy
[2025-05-09 03:37:26] Log sendo salvo em: /home/phil/Projects/k8s-noisy-lab/results/2025-05-09/03-37-26/cpu-noisy/experiment.log
[2025-05-09 03:37:26] Verificando pr√©-requisitos...
[2025-05-09 03:37:26] M√©tricas ser√£o salvas em: /home/phil/Projects/k8s-noisy-lab/results/2025-05-09/03-37-26/cpu-noisy
[2025-05-09 03:37:26] Validando recursos do cluster...
[0;35m==========================================[0m
[0;35m     VERIFICA√á√ÉO PR√â-EXPERIMENTO         [0m
[0;35m==========================================[0m
[0;35mVerificando conectividade com o cluster...[0m
[0;32m‚úì Conex√£o com o cluster estabelecida com sucesso[0m
[0;35mVerificando estado dos n√≥s do cluster...[0m
[0;32m‚úì O cluster possui 1 n√≥s dispon√≠veis[0m
[0;35mVerificando recursos dispon√≠veis no cluster...[0m
CPU: [0;35m11600[0m cores
Mem√≥ria: [0;35m30.73[0m GB
[0;32m‚úì Recursos do cluster s√£o suficientes para o experimento[0m
[0;35mVerificando namespaces necess√°rias...[0m
[0;32m‚úì Namespace 'tenant-a' encontrada[0m
[0;32m‚úì Namespace 'tenant-b' encontrada[0m
[0;32m‚úì Namespace 'tenant-c' encontrada[0m
[0;32m‚úì Namespace 'monitoring' encontrada[0m
[0;35mVerificando disponibilidade do Prometheus...[0m
[0;32m‚úì Prometheus est√° rodando e pronto[0m
[0;35mVerificando disponibilidade das m√©tricas essenciais...[0m
[0;32m‚úì M√©trica 'container_cpu_usage_seconds_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_memory_working_set_bytes' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_network_receive_bytes_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_network_transmit_bytes_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_cpu_cfs_throttled_periods_total' dispon√≠vel[0m
[0;32m‚úì M√©trica 'container_cpu_cfs_periods_total' dispon√≠vel[0m
[0;35mVerificando permiss√µes necess√°rias...[0m
[0;35mVerificando CRDs do Prometheus Operator...[0m
[0;32m‚úì CRD 'servicemonitors.monitoring.coreos.com' encontrada[0m
[0;32m‚úì CRD 'prometheusrules.monitoring.coreos.com' encontrada[0m
[0;35m==========================================[0m
[0;32m‚úì Cluster validado com sucesso para o experimento[0m
[0;35m==========================================[0m

Informa√ß√µes adicionais:
- O experimento utiliza m√©tricas da cAdvisor integradas ao kubelet
- As queries do Prometheus usam principalmente m√©tricas rate() com 1m de janela
- Os workloads s√£o distribu√≠dos em 3 tenants para simular o cen√°rio de noisy neighbour

Recomenda√ß√µes finais:
- Certifique-se de ter pelo menos 15-20% de recursos livres al√©m dos solicitados
- Se estiver usando Minikube, use a op√ß√£o '--driver=docker' para melhor desempenho
- Verifique se n√£o h√° outros processos consumindo recursos significativos nos n√≥s
[2025-05-09 03:37:30] Criando namespaces...
resourcequota/tenant-a-quota created
resourcequota/tenant-b-quota created
resourcequota/tenant-c-quota created
Warning: resource namespaces/tenant-a is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
namespace/tenant-a configured
Warning: resource namespaces/tenant-b is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
namespace/tenant-b configured
Warning: resource namespaces/tenant-c is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
namespace/tenant-c configured
[2025-05-09 03:37:30] Aplicando resource quotas...
resourcequota/tenant-a-quota configured
resourcequota/tenant-b-quota configured
resourcequota/tenant-c-quota configured
[2025-05-09 03:37:31] Stack de observabilidade j√° instalada.
[2025-05-09 03:37:31] Aguardando inicializa√ß√£o do Prometheus...
Error from server (NotFound): deployments.apps "prometheus-kube-prometheus-stack-prometheus" not found
[2025-05-09 03:37:31] N√£o foi poss√≠vel detectar o deployment do Prometheus. Continuando mesmo assim...
[2025-05-09 03:37:31] Configurando port-forward para o Prometheus...
Error from server (NotFound): services "prometheus-kube-prometheus-stack-prometheus" not found
[2025-05-09 03:37:36] Port-forward para Prometheus configurado com sucesso
[2025-05-09 03:37:36] ======= IN√çCIO DO EXPERIMENTO: cpu-noisy =======
[2025-05-09 03:37:36] Data: 2025/05/09, Hora: 03:37:26
[2025-05-09 03:37:36] N√∫mero de rounds: 1
[2025-05-09 03:37:36] Dura√ß√£o das fases: Baseline=60s, Ataque=120s, Recupera√ß√£o=60s
[2025-05-09 03:37:36] ===== ROUND 1/1 =====
[2025-05-09 03:37:36] === Fase 1: BASELINE ===
[2025-05-09 03:37:36] Limpando workloads anteriores...
[2025-05-09 03:37:46] Implantando tenant-a (refer√™ncia)...
deployment.apps/cpu-stress created
deployment.apps/memory-stress created
deployment.apps/iperf-server created
service/iperf-server created
[2025-05-09 03:37:46] Aguardando inicializa√ß√£o dos servi√ßos do tenant-a...
deployment.apps/iperf-server condition met
[2025-05-09 03:38:10] Implantando tenant-c (v√≠tima)...
deployment.apps/cpu-stress created
deployment.apps/memory-stress created
deployment.apps/iperf-client created
[2025-05-09 03:38:11] Aguardando inicializa√ß√£o dos workloads do tenant-c...
[2025-05-09 03:38:26] Coletando m√©tricas para a fase: baseline (Round 1)...
Traceback (most recent call last):
  File "/home/phil/Projects/k8s-noisy-lab/prometheus_metrics/main.py", line 10, in <module>
    from prometheus_metrics.metrics.container import ContainerMetricsCollector
ModuleNotFoundError: No module named 'prometheus_metrics'
